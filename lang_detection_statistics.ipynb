{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical approach to language detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import json\n",
    "import copy\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lan_code</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6910919</th>\n",
       "      <td>7301935</td>\n",
       "      <td>spa</td>\n",
       "      <td>Tom sale a caminar todos los días.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6487226</th>\n",
       "      <td>6872642</td>\n",
       "      <td>tok</td>\n",
       "      <td>jan li kama lukin e mun luka tu lon poka pi su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6665805</th>\n",
       "      <td>7054378</td>\n",
       "      <td>lat</td>\n",
       "      <td>Qui gratum dat ave, responsum fertque suave.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3280966</th>\n",
       "      <td>3494004</td>\n",
       "      <td>ind</td>\n",
       "      <td>Tom hampir dipecat dari pekerjaan.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8609110</th>\n",
       "      <td>9042616</td>\n",
       "      <td>nld</td>\n",
       "      <td>De dokter zal hem onderzoeken.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2946051</th>\n",
       "      <td>3122632</td>\n",
       "      <td>ita</td>\n",
       "      <td>Questo piatto si sposa molto bene con il sake.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8135194</th>\n",
       "      <td>8554319</td>\n",
       "      <td>por</td>\n",
       "      <td>Não consigo entender muitas de suas ações.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3439847</th>\n",
       "      <td>3662405</td>\n",
       "      <td>hin</td>\n",
       "      <td>मैं यूनान से हूँ।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3784454</th>\n",
       "      <td>4029465</td>\n",
       "      <td>tur</td>\n",
       "      <td>Benim zamanımda gerçek oyuncular vardı.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7596749</th>\n",
       "      <td>8004586</td>\n",
       "      <td>bel</td>\n",
       "      <td>Ён у цябе на стале.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id lan_code                                           sentence\n",
       "6910919  7301935      spa                 Tom sale a caminar todos los días.\n",
       "6487226  6872642      tok  jan li kama lukin e mun luka tu lon poka pi su...\n",
       "6665805  7054378      lat       Qui gratum dat ave, responsum fertque suave.\n",
       "3280966  3494004      ind                 Tom hampir dipecat dari pekerjaan.\n",
       "8609110  9042616      nld                     De dokter zal hem onderzoeken.\n",
       "2946051  3122632      ita     Questo piatto si sposa molto bene con il sake.\n",
       "8135194  8554319      por         Não consigo entender muitas de suas ações.\n",
       "3439847  3662405      hin                                  मैं यूनान से हूँ।\n",
       "3784454  4029465      tur            Benim zamanımda gerçek oyuncular vardı.\n",
       "7596749  8004586      bel                                Ён у цябе на стале."
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/sentences_10k_balanced.csv\", delimiter=\",\", encoding='utf8', index_col=0)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 2023529\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of rows: {len(df.index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = dict.fromkeys(i for i in range(sys.maxunicode) if unicodedata.category(chr(i)).startswith('P'))\n",
    "tbl[19968] = None\n",
    "\n",
    "chinese_punctuation = \"[\\u3002\\uff1b\\uff0c\\uff1a\\u201c\\u201d\\uff08\\uff09\\u3001\\uff1f\\u300a\\u300b\\uff01]\"\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    text = text.strip().lower().translate(tbl)\n",
    "    text = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \"\", text)\n",
    "    return re.sub(chinese_punctuation, \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentence'] = df['sentence'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lan_code</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>717324</th>\n",
       "      <td>751593</td>\n",
       "      <td>pol</td>\n",
       "      <td>wniósł kilka poprawek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7834972</th>\n",
       "      <td>8248641</td>\n",
       "      <td>ces</td>\n",
       "      <td>včera jsem nevečeřel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249835</th>\n",
       "      <td>1320266</td>\n",
       "      <td>tlh</td>\n",
       "      <td>rav lam yilamhachohmoh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6911739</th>\n",
       "      <td>7302770</td>\n",
       "      <td>rus</td>\n",
       "      <td>я не храню твоих фотографий</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4426361</th>\n",
       "      <td>4717937</td>\n",
       "      <td>jpn</td>\n",
       "      <td>ごめんって言ったじゃん</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10222187</th>\n",
       "      <td>10673670</td>\n",
       "      <td>dan</td>\n",
       "      <td>en rose er en smuk blomst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8263830</th>\n",
       "      <td>8685755</td>\n",
       "      <td>hin</td>\n",
       "      <td>उसका वज़न बढ़ रहा है</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123970</th>\n",
       "      <td>2251775</td>\n",
       "      <td>dan</td>\n",
       "      <td>det er helt forståeligt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696030</th>\n",
       "      <td>729159</td>\n",
       "      <td>por</td>\n",
       "      <td>a rainha elizabeth faleceu no ano de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7388558</th>\n",
       "      <td>7791169</td>\n",
       "      <td>ukr</td>\n",
       "      <td>я доволі прогресивний</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id lan_code                              sentence\n",
       "717324      751593      pol                 wniósł kilka poprawek\n",
       "7834972    8248641      ces                  včera jsem nevečeřel\n",
       "1249835    1320266      tlh                rav lam yilamhachohmoh\n",
       "6911739    7302770      rus           я не храню твоих фотографий\n",
       "4426361    4717937      jpn                           ごめんって言ったじゃん\n",
       "10222187  10673670      dan             en rose er en smuk blomst\n",
       "8263830    8685755      hin                  उसका वज़न बढ़ रहा है\n",
       "2123970    2251775      dan               det er helt forståeligt\n",
       "696030      729159      por  a rainha elizabeth faleceu no ano de\n",
       "7388558    7791169      ukr                 я доволі прогресивний"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {}\n",
    "\n",
    "for lang in df[\"lan_code\"].unique():\n",
    "    counts[lang] = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# long runtime\n",
    "\n",
    "for row in df.itertuples(index=False):\n",
    "    language = row[1]\n",
    "    sentence = row[2]\n",
    "    \n",
    "    for letter in sentence:\n",
    "        if letter == \" \":\n",
    "            continue\n",
    "        \n",
    "        counts[language][letter] += 1\n",
    "    \n",
    "    for idx in range(0, len(sentence) - 1):\n",
    "        letters = sentence[idx:idx+2]\n",
    "        \n",
    "        if \" \" in letters:\n",
    "            continue\n",
    "        \n",
    "        counts[language][letters] += 1\n",
    "    \n",
    "    for idx in range(0, len(sentence) - 2):\n",
    "        letters = sentence[idx:idx+3]\n",
    "        \n",
    "        if \" \" in letters:\n",
    "            continue\n",
    "        \n",
    "        counts[language][letters] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "print(len(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lan_code</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>cmn</td>\n",
       "      <td>我們試試看</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>cmn</td>\n",
       "      <td>我该去睡觉了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>cmn</td>\n",
       "      <td>你在干什麼啊</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>cmn</td>\n",
       "      <td>這是什麼啊</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>cmn</td>\n",
       "      <td>今天是６月１８号也是muiriel的生日</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>cmn</td>\n",
       "      <td>生日快乐muiriel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>cmn</td>\n",
       "      <td>muiriel现在20岁了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>cmn</td>\n",
       "      <td>密码是muiriel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>cmn</td>\n",
       "      <td>我很快就會回來</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>cmn</td>\n",
       "      <td>我不知道</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id lan_code              sentence\n",
       "0   1      cmn                 我們試試看\n",
       "1   2      cmn                我该去睡觉了\n",
       "2   3      cmn                你在干什麼啊\n",
       "3   4      cmn                 這是什麼啊\n",
       "4   5      cmn  今天是６月１８号也是muiriel的生日\n",
       "5   6      cmn           生日快乐muiriel\n",
       "6   7      cmn         muiriel现在20岁了\n",
       "7   8      cmn            密码是muiriel\n",
       "8   9      cmn               我很快就會回來\n",
       "9  10      cmn                  我不知道"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/counts_lang_wise_expanded_10k.json', 'w') as file:\n",
    "    json.dump(counts, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/counts_lang_wise_expanded.json', 'r') as file:\n",
    "#     counts = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counts2probability(counts: dict):\n",
    "    probabilities = {}\n",
    "    \n",
    "    for lang, lang_counts in counts.items():\n",
    "        total_lang_count = np.sum([lang_count for lang_count in lang_counts.values()])\n",
    "        one_sym_count = np.sum([1 for symbol in lang_counts.keys() if len(symbol) == 1])\n",
    "        sym_conut_compensation = [1, one_sym_count, one_sym_count**2]\n",
    "        \n",
    "        one_sym_lang_count = np.sum([lang_count for symbol, lang_count in lang_counts.items() if len(symbol) == 1])\n",
    "        two_sym_lang_count = np.sum([lang_count for symbol, lang_count in lang_counts.items() if len(symbol) == 2])\n",
    "        three_sym_lang_count = np.sum([lang_count for symbol, lang_count in lang_counts.items() if len(symbol) == 3])\n",
    "        sym_len_compensation = [one_sym_lang_count, two_sym_lang_count, three_sym_lang_count]\n",
    "        \n",
    "        for symbol_key, symbol_count in lang_counts.items():\n",
    "            if symbol_key not in probabilities.keys():\n",
    "                probabilities[symbol_key] = {}\n",
    "            \n",
    "            probabilities[symbol_key][lang] = symbol_count / sym_len_compensation[len(symbol_key) - 1]\n",
    "\n",
    "    for symbol_key, symbol_count in probabilities.items():\n",
    "        total_sym_count = np.sum([sym_count for sym_count in symbol_count.values()])\n",
    "        \n",
    "        for lang, lang_counts in symbol_count.items():\n",
    "            probabilities[symbol_key][lang] = lang_counts / total_sym_count\n",
    "            \n",
    "    return probabilities            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = counts2probability(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "846463\n"
     ]
    }
   ],
   "source": [
    "print(len(probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/probabilities_expanded_10k_second_method.json', 'w') as file:\n",
    "    json.dump(probabilities, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language_statistically(probabilities: dict, sentence: str):\n",
    "    sentence = remove_punctuation(sentence)\n",
    "    \n",
    "    symbols = list()\n",
    "    \n",
    "    for letter in sentence[1:]:\n",
    "        if letter != \" \":\n",
    "            symbols.append(letter)\n",
    "        \n",
    "    for idx in range(0, len(sentence) - 1):\n",
    "        if \" \" not in sentence[idx:idx+2]:\n",
    "            symbols.append(sentence[idx:idx+2])\n",
    "            \n",
    "    for idx in range(0, len(sentence) - 2):\n",
    "        if \" \" not in sentence[idx:idx+3]:\n",
    "            symbols.append(sentence[idx:idx+3])\n",
    "    \n",
    "    lang_probability = probabilities[sentence[0]]\n",
    "        \n",
    "    for symbol in tqdm(symbols, desc=\"Calculating language\"):\n",
    "        lang_probability_temp = copy.deepcopy(lang_probability)\n",
    "        \n",
    "        for lang_key in lang_probability.keys():\n",
    "            if lang_key not in probabilities[symbol].keys():\n",
    "                lang_probability_temp.pop(lang_key, None)\n",
    "        \n",
    "        lang_probability = copy.deepcopy(lang_probability_temp)\n",
    "        del lang_probability_temp\n",
    "        \n",
    "        for lang, probability in probabilities[symbol].items():\n",
    "            if lang not in lang_probability.keys():\n",
    "                continue\n",
    "            \n",
    "            lang_probability[lang] = lang_probability[lang] * probability\n",
    "        \n",
    "    prob_sum = np.sum([value for value in lang_probability.values()])\n",
    "    \n",
    "    for key, value in lang_probability.items():\n",
    "        lang_probability[key] = value/prob_sum\n",
    "        \n",
    "    return lang_probability\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/lan_to_language.json\", \"r\") as json_file:\n",
    "    lan2lang = json.load(json_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating language: 100%|██████████| 14/14 [00:00<00:00, 4665.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language for 'siemka': Polish\n",
      "\n",
      "All languages' probabilities:\n",
      "Polish: 0.9999991360791213\n",
      "Esperanto: 4.992771164215207e-07\n",
      "Czech: 2.3273961538653609e-07\n",
      "Danish: 8.151018084378243e-08\n",
      "Hungarian: 3.6908542725947506e-08\n",
      "Swedish: 1.3485423385814715e-08\n",
      "Mandarin Chinese: 9.685812208056373e-24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"siemka\"\n",
    "\n",
    "prob_lang = detect_language_statistically(probabilities, sentence)\n",
    "\n",
    "print(f\"Detected language for '{sentence}': {lan2lang[max(prob_lang, key=prob_lang.get)]}\\n\")\n",
    "\n",
    "print(\"All languages' probabilities:\")\n",
    "\n",
    "for lan, probability in dict(sorted(prob_lang.items(), key=lambda item: item[1], reverse=True)).items():\n",
    "    print(f\"{lan2lang[lan]}: {probability}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83fd4375a822156133a8f0ea701c86b5bfda9cc7c150a00174c57fbf773ec247"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
