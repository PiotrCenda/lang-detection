{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical approach to language detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import json\n",
    "import copy\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lan_code</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7996272</th>\n",
       "      <td>8413615</td>\n",
       "      <td>deu</td>\n",
       "      <td>Der Klimawandel begünstigt die Neozoenausbreit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3817542</th>\n",
       "      <td>4065402</td>\n",
       "      <td>hun</td>\n",
       "      <td>Ezt a filmet már legalább háromszor láttam.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3882481</th>\n",
       "      <td>4133904</td>\n",
       "      <td>mkd</td>\n",
       "      <td>Цел ден ми помина во чистење снег.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4857951</th>\n",
       "      <td>5183605</td>\n",
       "      <td>jbo</td>\n",
       "      <td>lo zdani be la tom cu se pagbu su'o zabna purdi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156913</th>\n",
       "      <td>162836</td>\n",
       "      <td>jpn</td>\n",
       "      <td>私の父は国内線のパイロットです。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6301864</th>\n",
       "      <td>6683826</td>\n",
       "      <td>ita</td>\n",
       "      <td>Tom probabilmente non è ancora affamato.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3390375</th>\n",
       "      <td>3610161</td>\n",
       "      <td>spa</td>\n",
       "      <td>El anciano probó el bálsamo con su lengua, y l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9894332</th>\n",
       "      <td>10343976</td>\n",
       "      <td>tlh</td>\n",
       "      <td>jatlhtaHvIS QIch wab Ho'DoS Sar nov qolbe'.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334155</th>\n",
       "      <td>349660</td>\n",
       "      <td>cmn</td>\n",
       "      <td>他在房子的周围看了看。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9497032</th>\n",
       "      <td>9943078</td>\n",
       "      <td>deu</td>\n",
       "      <td>Warum ist Tom nur so klug!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id lan_code                                           sentence\n",
       "7996272   8413615      deu  Der Klimawandel begünstigt die Neozoenausbreit...\n",
       "3817542   4065402      hun        Ezt a filmet már legalább háromszor láttam.\n",
       "3882481   4133904      mkd                 Цел ден ми помина во чистење снег.\n",
       "4857951   5183605      jbo    lo zdani be la tom cu se pagbu su'o zabna purdi\n",
       "156913     162836      jpn                                   私の父は国内線のパイロットです。\n",
       "6301864   6683826      ita           Tom probabilmente non è ancora affamato.\n",
       "3390375   3610161      spa  El anciano probó el bálsamo con su lengua, y l...\n",
       "9894332  10343976      tlh        jatlhtaHvIS QIch wab Ho'DoS Sar nov qolbe'.\n",
       "334155     349660      cmn                                        他在房子的周围看了看。\n",
       "9497032   9943078      deu                         Warum ist Tom nur so klug!"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/sentences_10k_balanced.csv\", delimiter=\",\", encoding='utf8', index_col=0)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 1788802\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of rows: {len(df.index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = dict.fromkeys(i for i in range(sys.maxunicode) if unicodedata.category(chr(i)).startswith('P'))\n",
    "tbl[19968] = None\n",
    "\n",
    "chinese_punctuation = \"[\\u3002\\uff1b\\uff0c\\uff1a\\u201c\\u201d\\uff08\\uff09\\u3001\\uff1f\\u300a\\u300b\\uff01]\"\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    text = text.strip().lower().translate(tbl)\n",
    "    text = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \"\", text)\n",
    "    return re.sub(chinese_punctuation, \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentence'] = df['sentence'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lan_code</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3544481</th>\n",
       "      <td>3771771</td>\n",
       "      <td>tur</td>\n",
       "      <td>keşke daha iyi şartlar altında görüşebilseydik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635381</th>\n",
       "      <td>665262</td>\n",
       "      <td>srp</td>\n",
       "      <td>on uvek nosi tamnu odeću</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10313927</th>\n",
       "      <td>10766530</td>\n",
       "      <td>pes</td>\n",
       "      <td>او صفت‌های خوب متعددی دارد</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056846</th>\n",
       "      <td>5398759</td>\n",
       "      <td>tat</td>\n",
       "      <td>яман үрнәк  йогышлы</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4719442</th>\n",
       "      <td>5032142</td>\n",
       "      <td>lat</td>\n",
       "      <td>lingua arabica maximi momenti est</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3506273</th>\n",
       "      <td>3731612</td>\n",
       "      <td>eng</td>\n",
       "      <td>where are those prisoners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3721503</th>\n",
       "      <td>3961683</td>\n",
       "      <td>ita</td>\n",
       "      <td>continuò a leggere il libro come se non fosse ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9114359</th>\n",
       "      <td>9556722</td>\n",
       "      <td>kab</td>\n",
       "      <td>ur teɛjil ara ɣer tamuqra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365896</th>\n",
       "      <td>382326</td>\n",
       "      <td>isl</td>\n",
       "      <td>hann ræktaði tómataplöntur úr fræjum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4820363</th>\n",
       "      <td>5142378</td>\n",
       "      <td>rus</td>\n",
       "      <td>у тома есть выбор</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id lan_code                                           sentence\n",
       "3544481    3771771      tur     keşke daha iyi şartlar altında görüşebilseydik\n",
       "635381      665262      srp                           on uvek nosi tamnu odeću\n",
       "10313927  10766530      pes                         او صفت‌های خوب متعددی دارد\n",
       "5056846    5398759      tat                                яман үрнәк  йогышлы\n",
       "4719442    5032142      lat                  lingua arabica maximi momenti est\n",
       "3506273    3731612      eng                          where are those prisoners\n",
       "3721503    3961683      ita  continuò a leggere il libro come se non fosse ...\n",
       "9114359    9556722      kab                          ur teɛjil ara ɣer tamuqra\n",
       "365896      382326      isl               hann ræktaði tómataplöntur úr fræjum\n",
       "4820363    5142378      rus                                  у тома есть выбор"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {}\n",
    "\n",
    "for lang in df[\"lan_code\"].unique():\n",
    "    counts[lang] = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# long runtime\n",
    "\n",
    "for row in df.itertuples(index=False):\n",
    "    language = row[1]\n",
    "    sentence = row[2]\n",
    "    \n",
    "    for letter in sentence:\n",
    "        if letter == \" \":\n",
    "            continue\n",
    "        \n",
    "        counts[language][letter] += 1\n",
    "    \n",
    "    for idx in range(0, len(sentence) - 1):\n",
    "        letters = sentence[idx:idx+2]\n",
    "        \n",
    "        if \" \" in letters:\n",
    "            continue\n",
    "        \n",
    "        counts[language][letters] += 1\n",
    "    \n",
    "    for idx in range(0, len(sentence) - 2):\n",
    "        letters = sentence[idx:idx+3]\n",
    "        \n",
    "        if \" \" in letters:\n",
    "            continue\n",
    "        \n",
    "        counts[language][letters] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "print(len(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lan_code</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>cmn</td>\n",
       "      <td>我們試試看</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>cmn</td>\n",
       "      <td>我该去睡觉了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>cmn</td>\n",
       "      <td>你在干什麼啊</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>cmn</td>\n",
       "      <td>今天是６月１８号也是muiriel的生日</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>cmn</td>\n",
       "      <td>muiriel现在20岁了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>cmn</td>\n",
       "      <td>密码是muiriel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>cmn</td>\n",
       "      <td>我不知道</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>cmn</td>\n",
       "      <td>我不知道應該說什麼才好</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>cmn</td>\n",
       "      <td>這個永遠完不了了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>cmn</td>\n",
       "      <td>我只是不知道應該說什麼而已</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id lan_code              sentence\n",
       "0    1      cmn                 我們試試看\n",
       "1    2      cmn                我该去睡觉了\n",
       "2    3      cmn                你在干什麼啊\n",
       "4    5      cmn  今天是６月１８号也是muiriel的生日\n",
       "6    7      cmn         muiriel现在20岁了\n",
       "7    8      cmn            密码是muiriel\n",
       "9   10      cmn                  我不知道\n",
       "10  11      cmn           我不知道應該說什麼才好\n",
       "11  12      cmn              這個永遠完不了了\n",
       "12  13      cmn         我只是不知道應該說什麼而已"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/counts_lang_wise_expanded.json', 'w') as file:\n",
    "    json.dump(counts, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counts2probability(counts: dict):\n",
    "    probabilities = {}\n",
    "    \n",
    "    for lang, lang_counts in counts.items():\n",
    "        total_lang_count = np.sum([lang_count for lang_count in lang_counts.values()])\n",
    "        one_sym_lang_count = np.sum([lang_count for symbol, lang_count in lang_counts.items() if len(symbol) == 1])\n",
    "        two_sym_lang_count = np.sum([lang_count for symbol, lang_count in lang_counts.items() if len(symbol) == 2])\n",
    "        three_sym_lang_count = np.sum([lang_count for symbol, lang_count in lang_counts.items() if len(symbol) == 3])\n",
    "        sym_len_compensation = [one_sym_lang_count, two_sym_lang_count, three_sym_lang_count]\n",
    "        \n",
    "        for symbol_key, symbol_count in lang_counts.items():\n",
    "            if symbol_key not in probabilities.keys():\n",
    "                probabilities[symbol_key] = {}\n",
    "            \n",
    "            # probabilities[symbol_key][lang] = symbol_count / total_lang_count * (len(symbol_key) * sym_len_compensation)\n",
    "            probabilities[symbol_key][lang] = symbol_count / sym_len_compensation[len(symbol_key) - 1]\n",
    "\n",
    "    for symbol_key, symbol_count in probabilities.items():\n",
    "        total_sym_count = np.sum([sym_count for sym_count in symbol_count.values()])\n",
    "        \n",
    "        for lang, lang_counts in symbol_count.items():\n",
    "            probabilities[symbol_key][lang] = lang_counts / total_sym_count\n",
    "            \n",
    "    return probabilities            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = counts2probability(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759319\n"
     ]
    }
   ],
   "source": [
    "print(len(probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/probabilities_expanded.json', 'w') as file:\n",
    "    json.dump(probabilities, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language_statistically(probabilities: dict, sentence: str):\n",
    "    sentence = remove_punctuation(sentence)\n",
    "    \n",
    "    symbols = list()\n",
    "    \n",
    "    for letter in sentence[1:]:\n",
    "        if letter != \" \":\n",
    "            symbols.append(letter)\n",
    "        \n",
    "    for idx in range(0, len(sentence) - 1):\n",
    "        if \" \" not in sentence[idx:idx+2]:\n",
    "            symbols.append(sentence[idx:idx+2])\n",
    "            \n",
    "    for idx in range(0, len(sentence) - 2):\n",
    "        if \" \" not in sentence[idx:idx+3]:\n",
    "            symbols.append(sentence[idx:idx+3])\n",
    "    \n",
    "    lang_probability = probabilities[sentence[0]]\n",
    "        \n",
    "    for symbol in tqdm(symbols, desc=\"Calculating language\"):\n",
    "        lang_probability_temp = copy.deepcopy(lang_probability)\n",
    "        \n",
    "        for lang_key in lang_probability.keys():\n",
    "            if lang_key not in probabilities[symbol].keys():\n",
    "                lang_probability_temp.pop(lang_key, None)\n",
    "        \n",
    "        lang_probability = copy.deepcopy(lang_probability_temp)\n",
    "        del lang_probability_temp\n",
    "        \n",
    "        for lang, probability in probabilities[symbol].items():\n",
    "            if lang not in lang_probability.keys():\n",
    "                continue\n",
    "            \n",
    "            lang_probability[lang] = lang_probability[lang] * probability\n",
    "        \n",
    "    prob_sum = np.sum([value for value in lang_probability.values()])\n",
    "    \n",
    "    for key, value in lang_probability.items():\n",
    "        lang_probability[key] = value/prob_sum\n",
    "        \n",
    "    return lang_probability\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/lan_to_language.json\", \"r\") as json_file:\n",
    "    lan2lang = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating language: 100%|██████████| 17/17 [00:00<00:00, 8502.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language for 'ragazzo': Hungarian\n",
      "All languages' probabilities: {'hun': 0.8178772781185304, 'ita': 0.18212272188143572, 'swe': 3.037131505662526e-14, 'ina': 3.726890418765009e-15, 'ces': 1.0632877669017078e-17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"ragazzo\"\n",
    "\n",
    "prob_lang = detect_language_statistically(probabilities, sentence)\n",
    "\n",
    "print(f\"Detected language for '{sentence}': {lan2lang[max(prob_lang, key=prob_lang.get)]}\")\n",
    "print(f\"All languages' probabilities: {dict(sorted(prob_lang.items(), key=lambda item: item[1], reverse=True))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83fd4375a822156133a8f0ea701c86b5bfda9cc7c150a00174c57fbf773ec247"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
